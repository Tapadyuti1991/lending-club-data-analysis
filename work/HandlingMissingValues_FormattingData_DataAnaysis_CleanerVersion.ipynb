{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#pip install seaborn \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vasanti\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (0,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/LoanStats3a_securev1.csv\",skiprows=1)\n",
    "#if more than 50% values in an observation is NAN drop that observation\n",
    "half_count = len(df.columns) / 2\n",
    "df=df.dropna(axis='columns', how='all')\n",
    "df = df.dropna(thresh=half_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "1  1077430  1314167.0     2500.0       2500.0           2500.0   60 months   \n",
       "3  1076863  1277178.0    10000.0      10000.0          10000.0   36 months   \n",
       "4  1075358  1311748.0     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "  int_rate  \n",
       "1   15.27%  \n",
       "3   13.49%  \n",
       "4   12.69%  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix[:5,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering using Technique 1 started\n"
     ]
    }
   ],
   "source": [
    "#Note: Refer to the report for detail description of the techniques\n",
    "print(\"Feature engineering using Technique 1 started\")\n",
    "#work on every feature slice-by-slice which one's are informative. We would drop some useless attributes and clean-up/modify others.\n",
    "# .ix[row slice, column slice]\n",
    "#df.ix[:4,:7]\n",
    "\n",
    "# We won't need id or member_id as it has no real predictive power so we can drop them from this table\n",
    "df=df.drop(['id','member_id'],1)\n",
    "\n",
    "# drop the record if loan_amnt, funded_amnt is missing\n",
    "df.loan_amnt=df.loan_amnt.dropna()\n",
    "df.funded_amnt=df.funded_amnt.dropna()\n",
    "\n",
    "# if the funded_amnt_inv is missing replace it with \n",
    "df.funded_amnt_inv=df.funded_amnt_inv.fillna(0)\n",
    "\n",
    "\n",
    "#int_rate was loaded as an object data type instead of float due to the '%' character. Let's strip that out and convert the column type.\n",
    "df.int_rate = pd.Series(df.int_rate).str.replace('%', '').astype(float)\n",
    "\n",
    "#replace missing values for Interest Rate with mean value\n",
    "df.int_rate=df.int_rate.fillna(float(df.int_rate.mean()))\n",
    "\n",
    "#term was loaded as an object data type instead of int due to the ' months' character. Let's strip that out and convert the column type.\n",
    "df.term=pd.Series(df.term).str.replace(' months', '')\n",
    "\n",
    "#replace missing values for Term with max value\n",
    "df.term=df.term.fillna(int(df['term'].value_counts().idxmax()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ryder</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Charged Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIR RESOURCES BOARD</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University Medical Group</td>\n",
       "      <td>1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  emp_title emp_length home_ownership  annual_inc  \\\n",
       "1                     Ryder   < 1 year           RENT     30000.0   \n",
       "3       AIR RESOURCES BOARD  10+ years           RENT     49200.0   \n",
       "4  University Medical Group     1 year           RENT     80000.0   \n",
       "\n",
       "  verification_status   issue_d  loan_status  \n",
       "1     Source Verified  Dec-2011  Charged Off  \n",
       "3     Source Verified  Dec-2011   Fully Paid  \n",
       "4     Source Verified  Dec-2011   Fully Paid  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix[:5,8:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the total number of value and unique values, total values are 42538 and unique values are 30660\n",
    "df.emp_title.shape\n",
    "df.emp_title.unique().shape\n",
    "\n",
    "#replace missing values for emp_title with Not available\n",
    "df.emp_title=df.emp_title.fillna(\"Not available\")\n",
    "\n",
    "#replacing missing values with 0\n",
    "df.emp_length.replace('n/a', np.nan,inplace=True)\n",
    "df.emp_length.fillna(value=0,inplace=True)\n",
    "\n",
    "#convert categorical value into numerical value\n",
    "df['emp_length'].replace(to_replace='[^0-9]+', value='', inplace=True, regex=True)\n",
    "df['emp_length'] = df['emp_length'].astype(int)\n",
    "\n",
    "#replace missing values for verification_status with Not verified\n",
    "df.verification_status=df.verification_status.fillna(\"Not verified\")\n",
    "\n",
    "#replace missing values for home_ownership with max value\n",
    "df.home_ownership=df.home_ownership.fillna(\"OTHER\")\n",
    "\n",
    "# drop the record if the annual_inc value is missing \n",
    "df.annual_inc=df.annual_inc.dropna()\n",
    "\n",
    "#replace missing values for issue_d with Not available\n",
    "df.issue_d=df.issue_d.fillna(\"Not available\")\n",
    "\n",
    "#replace missing values for loan_status with Not available\n",
    "df.loan_status=df.loan_status.fillna(\"Not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>url</th>\n",
       "      <th>desc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "      <td>https://lendingclub.com/browse/loanDetail.acti...</td>\n",
       "      <td>Borrower added on 12/22/11 &gt; I plan to use t...</td>\n",
       "      <td>car</td>\n",
       "      <td>bike</td>\n",
       "      <td>309xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n</td>\n",
       "      <td>https://lendingclub.com/browse/loanDetail.acti...</td>\n",
       "      <td>Borrower added on 12/21/11 &gt; to pay for prop...</td>\n",
       "      <td>other</td>\n",
       "      <td>personel</td>\n",
       "      <td>917xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>https://lendingclub.com/browse/loanDetail.acti...</td>\n",
       "      <td>Borrower added on 12/21/11 &gt; I plan on combi...</td>\n",
       "      <td>other</td>\n",
       "      <td>Personal</td>\n",
       "      <td>972xx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pymnt_plan                                                url  \\\n",
       "1          n  https://lendingclub.com/browse/loanDetail.acti...   \n",
       "3          n  https://lendingclub.com/browse/loanDetail.acti...   \n",
       "4          n  https://lendingclub.com/browse/loanDetail.acti...   \n",
       "\n",
       "                                                desc purpose     title  \\\n",
       "1    Borrower added on 12/22/11 > I plan to use t...     car      bike   \n",
       "3    Borrower added on 12/21/11 > to pay for prop...   other  personel   \n",
       "4    Borrower added on 12/21/11 > I plan on combi...   other  Personal   \n",
       "\n",
       "  zip_code  \n",
       "1    309xx  \n",
       "3    917xx  \n",
       "4    972xx  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix[:5,15:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#these four fields would not provide any important informaation thus we are dropping them\n",
    "df.drop(['pymnt_plan','url','desc','title','zip_code' ],1, inplace=True)\n",
    "#replace missing values for loan_status with Not available\n",
    "df.purpose=df.purpose.fillna(\"Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Apr-1999</td>\n",
       "      <td>740.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb-1996</td>\n",
       "      <td>690.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-1996</td>\n",
       "      <td>695.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dti  delinq_2yrs earliest_cr_line  fico_range_low  fico_range_high  \\\n",
       "1   1.00          0.0         Apr-1999           740.0            744.0   \n",
       "3  20.00          0.0         Feb-1996           690.0            694.0   \n",
       "4  17.94          0.0         Jan-1996           695.0            699.0   \n",
       "\n",
       "   inq_last_6mths  mths_since_last_delinq  mths_since_last_record  \n",
       "1             5.0                     NaN                     NaN  \n",
       "3             1.0                    35.0                     NaN  \n",
       "4             0.0                    38.0                     NaN  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix[:5,17:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace missing values for loan_status with Not available\n",
    "df.addr_state=df.addr_state.fillna(\"Not available\")\n",
    "#replace missing values for loan_status with Not available\n",
    "df.delinq_2yrs=df.delinq_2yrs.fillna(0)\n",
    "\n",
    "# drop the record if the fico_range_high and fico_range_low value is missing \n",
    "df.fico_range_low=df.fico_range_low.dropna()\n",
    "df.fico_range_high=df.fico_range_high.dropna()\n",
    "\n",
    "\n",
    "#FICO fico_range_low & fico_range_high scores on their own aren't as useful as a range thus we are considering its average\n",
    "df['fico_range'] = df.fico_range_low.astype('str') + '-' + df.fico_range_high.astype('str')\n",
    "df['meanfico'] = (df.fico_range_low + df.fico_range_high)/2\n",
    "# drop the features that are not relevant\n",
    "df.drop(['fico_range_low','fico_range_high','initial_list_status', 'mths_since_last_delinq','mths_since_last_record','pub_rec','open_acc'],1, inplace=True)\n",
    "\n",
    "#replace missing values for inq_last_6mths with 0\n",
    "df.inq_last_6mths=df.inq_last_6mths.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#from datetime import datetime\n",
    "\n",
    "#df.earliest_cr_line = pd.to_datetime(df.earliest_cr_line)\n",
    "\n",
    "#dttoday = datetime.now().strftime('%Y-%m-%d')\n",
    "# There is a better way to do this :) \n",
    "#df.earliest_cr_line = df.earliest_cr_line.apply(lambda x: (\n",
    " #       np.timedelta64((x - pd.Timestamp(dttoday)),'D').astype(int))/-365)\n",
    "\n",
    "#df.earliest_cr_line\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dti and open_acc is yet to be taken care @@@@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1014.530000</td>\n",
       "      <td>1014.53</td>\n",
       "      <td>456.46</td>\n",
       "      <td>435.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122.90</td>\n",
       "      <td>1.11</td>\n",
       "      <td>Apr-2013</td>\n",
       "      <td>119.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12231.890000</td>\n",
       "      <td>12231.89</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>2214.92</td>\n",
       "      <td>16.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jan-2015</td>\n",
       "      <td>357.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4066.908161</td>\n",
       "      <td>4066.91</td>\n",
       "      <td>3000.00</td>\n",
       "      <td>1066.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jan-2017</td>\n",
       "      <td>67.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10137.840008</td>\n",
       "      <td>10137.84</td>\n",
       "      <td>7000.00</td>\n",
       "      <td>3137.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>May-2016</td>\n",
       "      <td>1313.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3939.135294</td>\n",
       "      <td>3939.14</td>\n",
       "      <td>3000.00</td>\n",
       "      <td>939.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jan-2015</td>\n",
       "      <td>111.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1484.590000</td>\n",
       "      <td>1477.70</td>\n",
       "      <td>673.48</td>\n",
       "      <td>533.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>277.69</td>\n",
       "      <td>2.52</td>\n",
       "      <td>Nov-2012</td>\n",
       "      <td>121.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7678.017673</td>\n",
       "      <td>7678.02</td>\n",
       "      <td>6500.00</td>\n",
       "      <td>1178.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jun-2013</td>\n",
       "      <td>1655.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    out_prncp  out_prncp_inv   total_pymnt  total_pymnt_inv  total_rec_prncp  \\\n",
       "1         0.0            0.0   1014.530000          1014.53           456.46   \n",
       "3         0.0            0.0  12231.890000         12231.89         10000.00   \n",
       "4         0.0            0.0   4066.908161          4066.91          3000.00   \n",
       "6         0.0            0.0  10137.840008         10137.84          7000.00   \n",
       "7         0.0            0.0   3939.135294          3939.14          3000.00   \n",
       "9         0.0            0.0   1484.590000          1477.70           673.48   \n",
       "10        0.0            0.0   7678.017673          7678.02          6500.00   \n",
       "\n",
       "    total_rec_int  total_rec_late_fee  recoveries  collection_recovery_fee  \\\n",
       "1          435.17                0.00      122.90                     1.11   \n",
       "3         2214.92               16.97        0.00                     0.00   \n",
       "4         1066.91                0.00        0.00                     0.00   \n",
       "6         3137.84                0.00        0.00                     0.00   \n",
       "7          939.14                0.00        0.00                     0.00   \n",
       "9          533.42                0.00      277.69                     2.52   \n",
       "10        1178.02                0.00        0.00                     0.00   \n",
       "\n",
       "   last_pymnt_d  last_pymnt_amnt  \n",
       "1      Apr-2013           119.66  \n",
       "3      Jan-2015           357.48  \n",
       "4      Jan-2017            67.30  \n",
       "6      May-2016          1313.76  \n",
       "7      Jan-2015           111.34  \n",
       "9      Nov-2012           121.45  \n",
       "10     Jun-2013          1655.54  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix[:10,24:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace missing values for revol_bal with 0\n",
    "df.revol_bal=df.revol_bal.fillna(0)\n",
    "\n",
    "#replace missing values for revol_util with 0\n",
    "df.revol_util=df.revol_util.fillna(0)\n",
    "\n",
    "#replace missing values for total_acc with 0\n",
    "df.total_acc=df.total_acc.fillna(0)\n",
    "\n",
    "\n",
    "#revol_util was loaded as an object data type instead of float due to the '%' character. Let's strip that out and convert the column type.\n",
    "df.revol_util = pd.Series(df.revol_util).str.replace('%', '').astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0       33040\n",
      "1382.7        1\n",
      "Name: out_prncp_inv, dtype: int64\n",
      "0.00       33040\n",
      "1384.03        1\n",
      "Name: out_prncp, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#on checking the value count we see that majority portion of data is inclined towards one value thus these columns do not provide any relevant information, thus we are dropping the columns\n",
    "\n",
    "print(df.out_prncp_inv.value_counts())\n",
    "print(df.out_prncp.value_counts())\n",
    "\n",
    "df.drop(['out_prncp_inv','out_prncp'],1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#total_pymnt, total_pymnt_inv, total_rec_prncp, total_rec_int, total_rec_late_fee are not relevant in calculating the interest rate of the user, thus dropping them\n",
    "\n",
    "df.drop(['total_pymnt','total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee','recoveries','collection_recovery_fee','next_pymnt_d','last_credit_pull_d'],1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>fico_range</th>\n",
       "      <th>meanfico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>499.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>740.0-744.0</td>\n",
       "      <td>742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>690.0-694.0</td>\n",
       "      <td>692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>694.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>695.0-699.0</td>\n",
       "      <td>697.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   last_fico_range_high  last_fico_range_low  collections_12_mths_ex_med  \\\n",
       "1                 499.0                  0.0                         0.0   \n",
       "3                 604.0                600.0                         0.0   \n",
       "4                 694.0                690.0                         0.0   \n",
       "\n",
       "   policy_code application_type  acc_now_delinq  chargeoff_within_12_mths  \\\n",
       "1          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "3          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "4          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "\n",
       "   delinq_amnt  pub_rec_bankruptcies  tax_liens   fico_range  meanfico  \n",
       "1          0.0                   0.0        0.0  740.0-744.0     742.0  \n",
       "3          0.0                   0.0        0.0  690.0-694.0     692.0  \n",
       "4          0.0                   0.0        0.0  695.0-699.0     697.0  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix[:5,26:45]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculating the last mean fico score\n",
    "df['last_fico_range'] = df.last_fico_range_low.astype('str') + '-' + df.last_fico_range_high.astype('str')\n",
    "df['last_meanfico'] = (df.last_fico_range_low + df.last_fico_range_high)/2\n",
    "df.drop(['last_fico_range_high','last_fico_range_low','policy_code'],1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    33019\n",
      "Name: collections_12_mths_ex_med, dtype: int64\n",
      "INDIVIDUAL    33041\n",
      "Name: application_type, dtype: int64\n",
      "0.0    33038\n",
      "1.0        3\n",
      "Name: acc_now_delinq, dtype: int64\n",
      "0.0    33019\n",
      "Name: chargeoff_within_12_mths, dtype: int64\n",
      "0.0     33040\n",
      "27.0        1\n",
      "Name: delinq_amnt, dtype: int64\n",
      "0.0    29989\n",
      "1.0     1803\n",
      "2.0        8\n",
      "Name: pub_rec_bankruptcies, dtype: int64\n",
      "0.0    33040\n",
      "1.0        1\n",
      "Name: tax_liens, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#since the value count indicate majority of the data has just one value, we are dropping the column\n",
    "print(df.collections_12_mths_ex_med.value_counts())\n",
    "print(df.application_type.value_counts())\n",
    "print(df.acc_now_delinq.value_counts())\n",
    "print(df.chargeoff_within_12_mths.value_counts())\n",
    "print(df.delinq_amnt.value_counts())\n",
    "print(df.pub_rec_bankruptcies.value_counts())\n",
    "print(df.tax_liens.value_counts())\n",
    "\n",
    "df.drop(['acc_now_delinq','chargeoff_within_12_mths','delinq_amnt','pub_rec_bankruptcies','tax_liens','application_type','collections_12_mths_ex_med', 'grade'],1, inplace=True)\n",
    "#since the highest and lowest fico score is already considered, we can drop this field\n",
    "df.drop(['fico_range', 'last_fico_range'],1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate',\n",
      "       'installment', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership',\n",
      "       'annual_inc', 'verification_status', 'issue_d', 'loan_status',\n",
      "       'purpose', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line',\n",
      "       'inq_last_6mths', 'revol_bal', 'revol_util', 'total_acc',\n",
      "       'last_pymnt_d', 'last_pymnt_amnt', 'meanfico', 'last_meanfico'],\n",
      "      dtype='object')\n",
      "   loan_amnt  funded_amnt  funded_amnt_inv term  int_rate  installment  \\\n",
      "1       2500         2500           2500.0   60     15.27        59.83   \n",
      "3      10000        10000          10000.0   36     13.49       339.31   \n",
      "4       3000         3000           3000.0   60     12.69        67.79   \n",
      "6       7000         7000           7000.0   60     15.96       170.08   \n",
      "7       3000         3000           3000.0   36     18.64       109.43   \n",
      "\n",
      "  sub_grade                  emp_title  emp_length home_ownership  \\\n",
      "1        C4                      Ryder           1           RENT   \n",
      "3        C1        AIR RESOURCES BOARD          10           RENT   \n",
      "4        B5   University Medical Group           1           RENT   \n",
      "6        C5  Southern Star Photography           8           RENT   \n",
      "7        E1            MKC Accounting            9           RENT   \n",
      "\n",
      "       ...        delinq_2yrs earliest_cr_line inq_last_6mths revol_bal  \\\n",
      "1      ...                  0         Apr-1999              5      1687   \n",
      "3      ...                  0         Feb-1996              1      5598   \n",
      "4      ...                  0         Jan-1996              0     27783   \n",
      "6      ...                  0         Jul-2005              1     17726   \n",
      "7      ...                  0         Jan-2007              2      8221   \n",
      "\n",
      "  revol_util total_acc  last_pymnt_d  last_pymnt_amnt meanfico  last_meanfico  \n",
      "1        9.4         4      Apr-2013           119.66      742            249  \n",
      "3       21.0        37      Jan-2015           357.48      692            602  \n",
      "4       53.9        38      Jan-2017            67.30      697            692  \n",
      "6       85.6        11      May-2016          1313.76      692            652  \n",
      "7       87.5         4      Jan-2015           111.34      662            687  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Feature engineering using Technique 1 finished\n"
     ]
    }
   ],
   "source": [
    "#alter the dtypes of the column\n",
    "df.loan_amnt  =df.loan_amnt.astype(int)\n",
    "df.funded_amnt  =df.funded_amnt.astype(int)\n",
    "df.annual_inc  =df.annual_inc.astype(int)\n",
    "df.delinq_2yrs  =df.delinq_2yrs.astype(int)\n",
    "df.inq_last_6mths  =df.inq_last_6mths.astype(int)\n",
    "df.revol_bal  =df.revol_bal.astype(int)\n",
    "df.total_acc  =df.total_acc.astype(int)\n",
    "df.meanfico  =df.meanfico.astype(int)\n",
    "df.last_meanfico  =df.last_meanfico.astype(int)\n",
    "  \n",
    "#math.ceil(i*100)/100\n",
    "ceil_function= lambda x: math.ceil(x*100)/100\n",
    "df['funded_amnt_inv']=df['funded_amnt_inv'].apply(ceil_function)\n",
    "\n",
    "#after carefully examining each field we have shortlisted 28 features listed below\n",
    "tech1_df=df\n",
    "print(tech1_df.columns)\n",
    "print(tech1_df.head(5))\n",
    "print(\"Feature engineering using Technique 1 finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#using label encoder to convert categorical columns into numeric values\n",
    "def dummyEncode(data):\n",
    "        print(data.shape)\n",
    "        columnsToEncode = list(data.select_dtypes(include=['category','object']))\n",
    "        le = LabelEncoder()\n",
    "        for feature in columnsToEncode:\n",
    "            try:\n",
    "                data[feature] = le.fit_transform(data[feature])\n",
    "            except:\n",
    "                print('Error encoding '+feature)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'types'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-4110dff97346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#validating the performance of the model using Technique 1 extracted features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_orginal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_orginal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memp_title\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtech1_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_pymnt_d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vasanti\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2670\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'types'"
     ]
    }
   ],
   "source": [
    "#validating the performance of the model using Technique 1 extracted features\n",
    "\n",
    "print(df_orginal.id)\n",
    "print(type(df_orginal.emp_title))\n",
    "print(type(tech1_df.last_pymnt_d))\n",
    "\n",
    "#encode categorical fetaures to numeric using Label Encoding technique\n",
    "tech1_df=dummyEncode(tech1_df)\n",
    "df_orginal = pd.read_csv(\"Data/LoanStats3a_securev1.csv\",skiprows=1)\n",
    "#if more than 50% values in an observation is NAN drop that observation\n",
    "half_count = len(df_orginal.columns) / 2\n",
    "df_orginal=df_orginal.dropna(axis='columns', how='all')\n",
    "df_orginal = df_orginal.dropna(thresh=half_count)\n",
    "df_orginal=dummyEncode(df_orginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-0290f2f89651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtech1_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtech1_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memp_title\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_orginal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_pymnt_d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vasanti\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2670\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <td>0.057697</td>\n",
       "      <td>0.203557</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>-0.223102</td>\n",
       "      <td>-0.009468</td>\n",
       "      <td>-0.00105</td>\n",
       "      <td>0.122752</td>\n",
       "      <td>0.15693</td>\n",
       "      <td>-0.006197</td>\n",
       "      <td>0.178261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          annual_inc  verification_status   issue_d  loan_status   purpose  \\\n",
       "int_rate    0.057697             0.203557  0.004723    -0.223102 -0.009468   \n",
       "\n",
       "          addr_state       dti  delinq_2yrs  earliest_cr_line  inq_last_6mths  \n",
       "int_rate    -0.00105  0.122752      0.15693         -0.006197        0.178261  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute the corelation between the features to determine the relationship between all the features\n",
    "correlations_technique1 = tech1_df.corr(method='pearson')\n",
    "correlations_technique1.ix[4:5,10:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>url</th>\n",
       "      <th>purpose</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <td>0.03068</td>\n",
       "      <td>0.059134</td>\n",
       "      <td>0.211095</td>\n",
       "      <td>0.010701</td>\n",
       "      <td>-0.221493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>-0.00857</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>-0.001141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          home_ownership  annual_inc  verification_status   issue_d  \\\n",
       "int_rate         0.03068    0.059134             0.211095  0.010701   \n",
       "\n",
       "          loan_status  pymnt_plan       url  purpose  zip_code  addr_state  \n",
       "int_rate    -0.221493         NaN  0.002916 -0.00857  0.004878   -0.001141  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlations_technique2 = df_orginal.corr(method='pearson')\n",
    "# correlations_technique2.ix[5:6,10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_split_method(data):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data.ix[:, data.columns != 'int_rate'], data.int_rate, test_size=0.2, random_state=0)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_regression_model(x_train, x_test, y_train, y_test):\n",
    "    print(\"Starting Linear Regression algorithm\")\n",
    "    linear_reg = LinearRegression()\n",
    "    fit=linear_reg.fit(x_train, y_train)\n",
    "\n",
    "    print (\"Intercept is \",linear_reg.intercept_)\n",
    "    print(\"Coefficient is \",linear_reg.coef_)\n",
    "    #print(lm.predict([18,3,0,4]))\n",
    "    print(\"Training score is \",linear_reg.score(x_train, y_train))\n",
    "\n",
    "    #np.mean((linear_reg.predict(X_test)-Y_test)**2)\n",
    "    print(\"Testing score is \",linear_reg.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['grade'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-6a0b740e63ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#by checking the correaltion between these fetaures we can choose the features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtech1_list_of_variables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loan_amnt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'funded_amnt_inv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'term'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'grade'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sub_grade'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'verification_status'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'revol_util'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtech1_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtech1_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtech1_list_of_variables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m#random split method for creating the training and test splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vasanti\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1989\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1992\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vasanti\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2033\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2034\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2035\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2036\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vasanti\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s not in index'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['grade'] not in index\""
     ]
    }
   ],
   "source": [
    "#by checking the correaltion between these fetaures we can choose the features\n",
    "tech1_list_of_variables=['loan_amnt','funded_amnt_inv','term','grade','sub_grade','verification_status','revol_util']\n",
    "tech1_df=tech1_df[tech1_list_of_variables]\n",
    "\n",
    "#random split method for creating the training and test splits\n",
    "X_train, X_test, Y_train, Y_test = random_split_method(tech1_df)\n",
    "linear_regression_model(X_train, X_test, Y_train, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Note: Refer to the report for detail description of the techniques\n",
    "print(\"Feature engineering using Technique 2 started\")\n",
    "\n",
    "cols = df.columns\n",
    "# #getting the list of features that are numeric\n",
    "# num_cols_list = df._get_numeric_data().columns\n",
    "\n",
    "# #getting the list of features that are categorical\n",
    "# cat_cols_list=list(set(cols) - set(num_cols_list))\n",
    "# #print(df[cat_cols_list])\n",
    "\n",
    "# #print(\"Next one\")\n",
    "# #print(df[num_cols_list])\n",
    "# #X=df[num_cols_list].ix[:, df[num_cols_list].columns != 'int_rate']\n",
    "\n",
    "\n",
    "# df[cat_cols_list]=dummyEncode(df[cat_cols_list])\n",
    "\n",
    "\n",
    "\n",
    "# X=df.ix[:, df.columns != 'int_rate']\n",
    "# Y=df.int_rate\n",
    "\n",
    "# X=X.as_matrix()\n",
    "# Y=Y.as_matrix()\n",
    "\n",
    "# #Describe each features distribution  @@@ uncomment this later\n",
    "# #print(df.describe())\n",
    "\n",
    "# #Compute the corelation between the features to determine the relationship between all the features\n",
    "# correlations = df.corr(method='pearson')\n",
    "# #print(correlations.ix[4:5,25:35])\n",
    "\n",
    "# new_df= pd.read_csv(\"Data/LoanStats3a_securev1.csv\",skiprows=1)\n",
    "# new_df=new_df.dropna(axis='columns', how='all')\n",
    "# new_df = new_df.dropna()\n",
    "# new_df=dummyEncode(new_df)\n",
    "\n",
    "# correlations2 = new_df.corr(method='pearson')\n",
    "# correlations2.ix[6:7,59:65]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #@@@not working\n",
    "\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import chi2\n",
    "# feature_test = SelectKBest(score_func=chi2, k=4)\n",
    "\n",
    "# fit = feature_test.fit(X, Y)\n",
    "\n",
    "# print(\"Selected Features: %s\") % fit.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "lr = LinearRegression()\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "sfs = SFS(lr, \n",
    "          k_features=13, \n",
    "          forward=True, \n",
    "          floating=False, \n",
    "          scoring='neg_mean_squared_error',\n",
    "          cv=10)\n",
    "\n",
    "sfs = sfs.fit(X, Y)\n",
    "fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Funded_amt_inv\n",
    "#Term\n",
    "#Grade\n",
    "#Subgrade\n",
    "#Dti\n",
    "#Delinq_2_yrs\n",
    "#Total_payment_inv\n",
    "#Total_rec_int\n",
    "\n",
    "\n",
    "# new_df= pd.read_csv(\"Data/LoanStats3a_securev1.csv\",skiprows=1)\n",
    "# new_df=new_df.dropna(axis='columns', how='all')\n",
    "# new_df = new_df.dropna()\n",
    "# new_df=dummyEncode(new_df)\n",
    "\n",
    "#Y_train=df.int_rate\n",
    "my_list=['loan_amnt','funded_amnt_inv','term','grade','sub_grade','verification_status','revol_util']\n",
    "\n",
    "#X_train=df\n",
    "#random split method for creating the training and test splits\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.ix[:, df.columns != 'int_rate'], df.int_rate, test_size=0.2, random_state=0)\n",
    "\n",
    "print(len(df))\n",
    "print(len(Y_train))\n",
    "\n",
    "print(len(X_test))\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "print(\"Starting Linear Regression algorithm\")\n",
    "linear_reg = LinearRegression()\n",
    "fit=linear_reg.fit(X_train, Y_train)\n",
    "\n",
    "print (\"Intercept is \",linear_reg.intercept_)\n",
    "print(\"Coefficient is \",linear_reg.coef_)\n",
    "#print(lm.predict([18,3,0,4]))\n",
    "print(\"Training score is \",linear_reg.score(X_train, Y_train))\n",
    "\n",
    "#np.mean((linear_reg.predict(X_test)-Y_test)**2)\n",
    "print(\"Testing score is \",linear_reg.score(X_test, Y_test))\n",
    "\n",
    "train_scores = cross_val_score(fit, df.ix[:, df.columns != 'int_rate'], df.int_rate, cv=10)\n",
    "print(train_scores)\n",
    "\n",
    "#Simple K-Fold cross validation. 10 folds.\n",
    "print(X_train.shape)\n",
    "cv = cross_validation.KFold(len(X_train), n_folds=10)\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# X_train=X_train.as_matrix()\n",
    "# Y_train=Y_train.as_matrix()\n",
    "\n",
    "# \"Error_function\" can be replaced by the error function of your analysis\n",
    "for traincv, testcv in cv:\n",
    "        print(X_train[800])\n",
    "        probas = linear_reg.fit(X_train[traincv], Y_train[traincv])\n",
    "        #results.append( Error_function )\n",
    "        \n",
    "print (\"Results: \" + str( np.array(probas).mean() ))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
